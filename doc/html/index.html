<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Directed Acyclic Graph Frame Scheduler.</title>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="DoxyStyle.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script> 
</head>
<body onload='searchBox.OnSelectItem(0);'>
<div id="top"><!-- do not remove this div! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;" nowrap="nowrap">
   <div id="projectname"><a href="http://blacktoppstudios.com"><img src="logogreen100pxtall.png" /></a>DAGFrameScheduler&#160;<span id="projectnumber">September 2013</span></div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Directed Acyclic Graph Frame Scheduler. </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="goal_sec"></a>
Goals</h1>
<p>This library tries to make writing multithreaded software easier by changing the kinds of primitives that multithreaded software is built upon. Several libraries before this have attempted this already. This library is different becuse it focuses on a specific kind of workload and provides the kinds of guarantees that the workload needs while sacrificing other guarantees that the workload does not need. <br/>
 <br/>
 This attempts to provide a multithreading solution for workloads that must be run in many iterations in a given amount of realtime. Games are an ideal example. Every frame a video game must update physics simulations, make AI decisions, accept/interpret user input, enforce game rules, perform dynamic I/O and render it to the screen all while maintaining a smooth FrameRate and do that while minimizing drain to batteries on portable devices (sometimes without even knowing if the device is portable). <br/>
 <br/>
 This library accomplishes those goals by removing the conventional mutlithreading primitives that so many developers have come to fear, loathe, or misunderstand. Mutexes, threads, memory fences, thread_local storage, atomic variables, and all the pitfalls that come with them are replaced by a small set of of primitives that provide all the required sophistication a typical multi-threaded application requires. It does this using a new kind of <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>, <a class="el" href="classMezzanine_1_1Threading_1_1DoubleBufferedResource.html">Double Buffering</a>, a strong concept of dependencies and a <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> that uses heuristics to decide how to run it all without exposing needless complexity to the application developer.</p>
<h1><a class="anchor" id="overview_sec"></a>
Overview</h1>
<p>The DAGFrameScheduler is a variation on a common multithreaded work queue. It seeks to avoid its pitfalls, such as non-determinism, thread contention, and lackluster scalability while keeping its advantages including simplicity, understandiblity, and low overhead. <br/>
 <br/>
 With this algorithm very few, if any, calls will need to be made to the underlying system for synchronization of the actual work to be performed. Instead, this library will provide limited (not always, but for constistent workloads) deterministic ordering of <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> execution through a dependency feature. Having the knowledge that one <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> will complete after another allows for resources to be used without using expensive and complex synchronization mechansisms like <a class="el" href="classMezzanine_1_1Threading_1_1Mutex.html">mutexes</a>, semaphores, or even an <a class="el" href="namespaceMezzanine_1_1Threading.html#a176b8e4ae356f3bfb7630c4819fa021b">Atomic Compare And Swaps</a>. These primitives are provided to allow use of this library in advanced ways for developers who are already familiar with multithreaded systems. <br/>
 <br/>
 The internal work queue is not changed while a frame is executing. Because it is only read, each thread can pick its own work. Synchronization still needs to occur, but it has been moved onto each <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> amd is managed with atomic CPU operations. Like this, contention is less frequent occurring only when threads simultaneously attempt to start the same <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>. This consumes far less time because atomic operations are CPU instructions instead of Operating System calls. This is managed by the library, so individual <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>s do not need to worry synchronization beyond telling each <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> about its data dependencies and making sure all the <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>s are added to a <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a>.</p>
<h1><a class="anchor" id="broken_sec"></a>
Broken Algorithms</h1>
<p>To understand why a new multithreading system is needed, it is helpful to look at other methods of threading that have been used in the past. This can give us an understanding of what they lack or how they aren't ideal for the kinds of work this algorithm is intended for. This overview is intentionally simplified. There are variations on many of these algorithms that can fix some of the problems presented. Despite these workarounds there are fundamental limitations that prevent these algorithms from being ideal for video games, simulations and similar tasks. These threading models aren't necessarily broken, as some of these clearly have a place in software development. Many of these require complex algorithms, require subtle knowledge, or simply aren't performant enough for realtime environments. <br/>
 <br/>
 I will use charts that plot possible resource use of a computer across time. Generally time will run across the top as resources, usually CPUs, will run down one side. Most of these algorithms have a concept of tasks or workunits, which are just pieces of work with a distinct begining and end. The width of a piece of work loosely represents the execution time (the names are just for show and not related to anything real). </p>
<h2><a class="anchor" id="broken_Single"></a>
Single Threaded</h2>
<p>An application using this threading model is not actually multithreaded at all. However, It has been shown that software can run in a single and get good perfomance. This is the benchmark all other threading models get compared too. <br/>
 <br/>
 There is a term, Speedup ( <a href="http://en.wikipedia.org/wiki/Speedup">http://en.wikipedia.org/wiki/Speedup</a> ), which is simply a comparison of the single threaded performance of an algorithm to the mutlithreaded performance. You simply determine how many times more work the multithreaded algorithm does in the same time, or how many times longer the single threaded algorithm takes to the same work. Ideally two threads will be twice as fast (speedup of 2x), and three thread would be three times as fast (3x speedup), and so; this is called linear speedup. In practice there is always some overhead in creating and synchronizing threads, so achieving linear speedup is difficult. <br/>
 <br/>
 </p>
<div class="image">
<img src="Single.png" alt="Single.png"/>
<div class="caption">
Single Threaded Execution - Fig 1.</div></div>
<br/>
 <br/>
 The DAGFrameScheduler library tries to tailor the threading model to a specific problem to minimize that overhead. With a single threaded application one thread does all the work and always wastes every other thread, but there is no overhead if the system only has one thread. <br/>
 <br/>
 </p>
<h2><a class="anchor" id="broken_Unplanned"></a>
Unplanned Thread</h2>
<p>Sometimes someone means well and tries to increase the performance of a single threaded program and tries to add extra threads to increase performance. Sometimes this works really well and sometimes there is a marginal increase in performance or a significant increase in bugs. If that someone has a good plan then they can usually achieve close to the best speedup possible in the given situation. This is not easy and many cannot do this or do not want to invest the time it would take. If not carefully planned bugs like deadlock ( <a href="http://en.wikipedia.org/wiki/Deadlock">http://en.wikipedia.org/wiki/Deadlock</a> ) and race conditions ( <a href="http://stackoverflow.com/questions/34510/what-is-a-race-condition">http://stackoverflow.com/questions/34510/what-is-a-race-condition</a> ) can be introduced. Unfortunately no amount of testing can replace this careful planning. Without a complete understanding of how multithreaded software is assembled (a plan) it is not possible to prove that multithreaded software will not hang/freeze or that it will produce the correct results. <br/>
 <br/>
 Software with no multithreading plan could have just about any kind of execution behavior. Usually unplanned software performs at least slightly better than single threaded versions of the software, but frequently does not utilize all the available resources. Generally performance does not scale well as unplanned software is run on more processors. Frequently, there is contention for a specific resource and a thread will wait for that resource longer than is actually needed. </p>
<div class="image">
<img src="Unplanned.png" alt="Unplanned.png"/>
<div class="caption">
Unplanned Threaded Execution - Fig 2.</div></div>
<br/>
 <br/>
 The DAGFrameScheduler is carefully planned and completely avoids costly synchronization mechanisms in favor of less costly minimalistic ones. Marking one <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> as dependent on another allows the reordering of <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnits</a> so that some <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> can be executed with no thread waiting or blocking. <br/>
 <br/>
 </p>
<h3><a class="anchor" id="broken_TaskPerThread"></a>
One Task Per Thread</h3>
<p>A common example of poor planning is the creation of one thread for each task in a game. Despite being conceptually simple, performance of systems designed this way is poor due to synchronization and complexities that synchronization requires. </p>
<h2><a class="anchor" id="broken_ConventionWorkQueue"></a>
Convention Work Queue/Thread Pools</h2>
<p>Conventional work queues and thread pools are a well known and robust way to increase the throughput of of an application. These are ideal solutions for many systems, but not games. <br/>
 <br/>
 In conventional workqueues all of the work is broken into a number of small thread-safe units. As these units are created they are stuffed into a queue and threads pull out units of work as it completes other units it has started. This simple plan has many advantages. If there is work to do then at least one thread will be doing some, and usually more threads will be working. This is good for games and the DAGFrameScheduler mimics it. If the kind of work is unknown when the software is written heuristics and runtime decisions can create the kind of units of work that are required. This is not the case with games and the others kinds of software this library caters to, so changes can be made that remove the problems this causes. One such drawback is that a given unit of work never knows if another is running or has completed, and must therefor make some pessimistic assumptions. </p>
<div class="image">
<img src="Threadpool.png" alt="Threadpool.png"/>
<div class="caption">
Convention Work Queue/ThreadPools - Fig 3.</div></div>
<br/>
 <br/>
 Common synchronization mechanisms like mutexes or semaphores block the thread for an unknown amount of time, and are required by the design of workqueues. There are two times this is required. The first time is whenever a work unit is acquired by a thread, a mutex (or similar) must be used to prevent other threads from modifying the queue as well. This impacts scalability, but can be circumvented to a point. Common ways to work around this try to split up the work queue pre-emptively, or feed the threads work units from varying points in the queue. The DAGFrameScheduler moves the synchronizantion onto each work unit to greatly reduce the contention as more work units are added. <br/>
 <br/>
 The other, and less obvious, point of contention that has not be circumvented in a satisfactory way for games is the large of amount of synchronization required between units of work that must communicate. For example, there may be hundreds of thousands of pieces of data that must be passed from a system into a 3d rendering system. Applying mutexes to each would slow execution an impossibly long time (if it didn't introduce deadlock), while more coarse grained lock would prevent large portions of physics and rendering from occurring at the time causing one or both of them to wait/block. A simple solution would be to run physics before graphics, but common work queues do not provide good guarantees in this regard. <br/>
 <br/>
 The DAGFrameScheduler was explicitly designed to provide exactly this guarantee. If the physics <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> is added to the graphics <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> with <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html#a50857c855830486d34dd1f00744a5765">AddDependency(WorkUnit*)</a> then it will always be run before the graphics workunit in a given frame. The drawback of this is that it is more difficult to make runtime creation of workunits (It is possible but it cannot be done during any frame execution), but completely removes the locking mechanisms of conventional work queues. The DAGFrameScheduler has traded one useless feature for a useful guarantee.</p>
<h1><a class="anchor" id="algorithm_sec"></a>
The Algorithm</h1>
<p>When first creating the DAGFrameScheduler it was called it "Dagma-CP". When describing it the phrase "Directed Acyclic Graph Minimal Assembly of Critical Path" was used. If you are lucky enough to knows what all those terms mean when assembled this way they are very descriptive. For rest of us the algorithm tries to determine what is the shortest way to execute the work in a minimalistic way using a mathematical graph. The graph is based on what work must done before other work each frame and executing it. All the work in this graph will have a location somewhere between the beginning and end, and will never circle around back so it can be called acyclic. <br/>
 <br/>
 This algorithm was designed with practicality as the first priority. To accomodate and integrate with a variety of other algorithms and system a variety of Work Units are provided. New classes can be created that inherit from these to allow them to be in the scheduler where they will work best. </p>
<ul>
<li><a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> - The interface for a common workunit. These work units will be executed once each frame after all their dependencies have completed. These are also expected to complete execution in a relatively brief period of time compared to the length of a frame, and create no threads while doing so. </li>
<li><a class="el" href="classMezzanine_1_1Threading_1_1DefaultWorkUnit.html">DefaultWorkUnit</a> - A simple implementation of an <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>. This may not be suitable for every use case, but it should be suitable for most. Just one function for derived classes to implement, the one that does actual work. </li>
<li><a class="el" href="classMezzanine_1_1Threading_1_1iAsynchronousWorkUnit.html">iAsynchronousWorkUnit</a> - Intended to allow loading of files and streams even after the framescheduler has paused. Work units are to spawn one thread and manage it without interfering with other execution. DMA, and other hardware coprocessors are expected to be utilized to their fullest to help accomplish this. </li>
<li><a class="el" href="classMezzanine_1_1Threading_1_1MonopolyWorkUnit.html">MonopolyWorkUnit</a> - These are expected to monopolize cpu resources at the beginning of each frame. This is ideal when working with other systems. For example a phsyics system like Bullet3D. If the calls to a physics system are wrapped in a <a class="el" href="classMezzanine_1_1Threading_1_1MonopolyWorkUnit.html">MonopolyWorkUnit</a> then it will be given full opportunity to run before other work units.</li>
</ul>
<p>Once all the <a class="el" href="classMezzanine_1_1Threading_1_1MonopolyWorkUnit.html">MonopolyWorkUnit</a>s are done then the <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> class instance spawns or activates a number of threads based on a simple heuristic. This heuristic is the way work units are sorted in preparation for execution. To understand how these are sorted, the dependency system needs to be understood. <br/>
 <br/>
 Most other work queues do not provide any guarantee about the order work will be executed in. This means that each piece of work must ensure its own data integrity using synchronization primitives like mutexes and semaphores to protect from being corrupted by multithread access. In most cases these should be removed and one of any two work units that must read/write the data must depend on the other. This allows the code in the workunits to be very simple even if it needs to use a great deal of data other work units may also consume or produce. <br/>
 <br/>
 Once all the dependencies are in place for any synchronization that has been removed, a <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> can be created and started. At runtime this creates a reverse dependency graph, a <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a3480908d1f06458466b312857570e3cf">DependentGraph</a>. This is used to determine which work units are the most depended upon. For each work unit a simple count of how many work units cannot start until has been completed is generated. The higher this number the earlier the work unit will be executed in a frame. Additionally workunits that take longer to execute will be prioritized ahead of work units that are faster. <br/>
 <br/>
 Here is a chart that provides an example of this re-factoring and the runtime sorting process: </p>
<div class="image">
<img src="DAGSorting.png" alt="DAGSorting.png"/>
<div class="caption">
DAG WorkSorting - Fig 4.</div></div>
<br/>
 <br/>
 There are several advantages this sorting provides that are not immediately obvious. It separates the scheduling from the execution allowing the relatively costly sorting process to be executed only when work units are added, removed, or changed. Prioritizing Workunits that take longer to run should help insure the shortest critical path is found by minimizing how often dependencies cause threads to wait for more work. <br/>
 <br/>
 Sorting the work can be done by a manual call to <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a518ad64baf64d3dde2819aa580055249">FrameScheduler::SortWorkUnitsAll()</a>, <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a9f2e92ae7cbd9e4179da6aa895d766fe">FrameScheduler::SortWorkUnitsMain()</a>, <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a80628895bdad74d03e5ac3b247e58741">FrameScheduler::SortWorkUnitsAffinity()</a> or by adding a <a class="el" href="classMezzanine_1_1Threading_1_1WorkSorter.html">WorkSorter</a> WorkUnit to the <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a>. This only needs to be done when work units have been added, removed, or their times are likely to have changed. <br/>
 <br/>
 Each thread queries the <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> for the next piece of work. The <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> maintains the list of work units and the next available piece of work can be retrieved with <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#ad4b969aa874a74fa503518d5e0b3a3bc">FrameScheduler::GetNextWorkUnit()</a> or <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a63ecabada780522819ca611399e806c6">FrameScheduler::GetNextWorkUnitAffinity()</a>. This by itself is not the atomic operation that allows the thread to execute the workunit, instead <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html#aaf745da02fb9519cb453134846e1fde4">iWorkUnit::TakeOwnerShip()</a> can grant that. Internally this uses an <a class="el" href="namespaceMezzanine_1_1Threading.html#a176b8e4ae356f3bfb7630c4819fa021b">Atomic Compare And Swap</a> operation to maximize performance. By having the workunit manage the right to execute it removes the work queue as the primary source of contention that would prevent scaling. This does add another potential point of slowdowns though; threads must iterate over each other workunit until they reach the work to be executed. If atomic operations are used to maintain an iterator that keeps track of where to start searching for work, in a waitfree way, then we can trade the cost of this iteration for a number of atomic operations. On some systems this is a great idea, on others a terrible idea, so it is a <a class="el" href="crossplatformexport_8h.html#a491f7cf4e0e45f1f6e9a0098eff815a0">CMake option called DecachingWork</a>. Because this update can be skipped if it work incur a wait, it does not recreate a central workqueue's primary point of contention while providing all the benefits. </p>
<div class="image">
<img src="DAGThreads.gif" alt="DAGThreads.gif"/>
<div class="caption">
DAG threads - Fig 5.</div></div>
<p><br/>
 <br/>
 Some work must be run on specific threads, such as calls to underlying devices (for example, graphics cards using Directx or OpenGL). These <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>s are put into a different listing where only the main thread will attempt to execute them. Other than running these, and running these first, the behavior of the main thread is very similar to other threads. <br/>
 <br/>
 Even much of the <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a>'s work is performed in <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>s, such as log aggregation and <a class="el" href="classMezzanine_1_1Threading_1_1WorkSorter.html">Sorting the work listing</a>. <a class="el" href="classMezzanine_1_1Threading_1_1iAsynchronousWorkUnit.html">iAsynchronousWorkUnit</a>s continue to run in a thread beyond normal scheduling and are intended to consume fewer CPU resources and more IO resources. For example loading a large file or listening for network traffic. These will be normal <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a>s in most regards and will check on the asynchronous tasks they manage each frame when they run as a normally scheduled. <br/>
 <br/>
 If a thread runs out of work because all the work is completed the frame will pause until it should start again the next frame. This pause length is calulated using a runtime configurable value on the <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a>. If a thread has checked every <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> and some are still not executing, but could not be started because of incomplete dependencies the thread will simply iterate over every <a class="el" href="classMezzanine_1_1Threading_1_1iWorkUnit.html">iWorkUnit</a> in the <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> until the dependencies of one are met and allows one to be executed. This implicitly guarantees that at least one thread will always do work, and if dependencies chains are kept short then it is more likely that several threads will advance. </p>
<h1><a class="anchor" id="algorithmintegrate_sec"></a>
Integrating with the Algorithm</h1>
<p>When <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a93e8f9d384197837fcf8fc0f3c058a5c">FrameScheduler::DoOneFrame()</a> is called several things happen. All work units are executed, all threads are paused until the this frame has consumed the amount of time it should, and the timer is restarted for the next frame. <br/>
 <br/>
 This process is actually divided into six steps. The function <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a93e8f9d384197837fcf8fc0f3c058a5c">FrameScheduler::DoOneFrame()</a> simply calls the following functions: </p>
<h2><a class="anchor" id="integrate1"></a>
Step 1 - Run All the Monopolies</h2>
<p>The function <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#ac8dfbc810d2d24bf4c5ba4bec6c08b5c">FrameScheduler::RunAllMonopolies()</a> simply iterates through all the <a class="el" href="classMezzanine_1_1Threading_1_1MonopolyWorkUnit.html">MonopolyWorkUnit</a> that have been added with <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#add1449feaeebf3ecef327a9cbed9b890">FrameScheduler::AddWorkUnitMonopoly()</a>. It does this in no specific order. <br/>
 <br/>
 In general <a class="el" href="classMezzanine_1_1Threading_1_1MonopolyWorkUnit.html">MonopolyWorkUnit</a>s can be expected to use all available CPU resources. Other threads should not be executed in general. </p>
<h2><a class="anchor" id="integrate2"></a>
Step 2 - Create and Start Threads</h2>
<p>The function <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#aa2cc09939a4779cbb6c0affcb0b1431e">FrameScheduler::CreateThreads()</a> Creates enough threads to get to the amount set by <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a4f444bf0555ec26f1af052ea5e056e9f">FrameScheduler::SetThreadCount()</a> . Depending on how this library is configured this could mean either creating that many threads each frame or creating additional threads only if this changed. <br/>
 <br/>
 Regardless of the amount of threads created, all but one of them will start executing work units as described in the section <a class="el" href="index.html#algorithm_sec">The Algorithm</a>. This will execute as much work as possible (work units with affinity can affect how much work can be done with out waiting) that was added by <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a3096193b64c75e185400a6d011bc0e6a">FrameScheduler::AddWorkUnitMain</a>. If there is only one thread, the main thread, then this will return immediately and no work will be done. </p>
<h2><a class="anchor" id="integrate3"></a>
Step 3 - Main Thread Work</h2>
<p>The call to <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a27b7bda2596fbbf669143688398f1fa5">FrameScheduler::RunMainThreadWork()</a> will start the main thread executing work units. This is the call that executes work units added with <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a0df64d2a90622056d94284eda250c975">FrameScheduler::AddWorkUnitAffinity</a>. <br/>
 <br/>
 If you have single thread work that is not part of a work unit and will not interfere with and work units execution then you can run it before calling this. Be careful when doing this, if there are any work units that depend on work units with affinity then they will not be able to start until some point after this is called. <br/>
 <br/>
 Once every work unit has started this call can return. This does not mean every work unit is complete, though every work unit with affinity will be complete. There could be work in other threads still executing. This is another good point to run work that is single threaded and won't interfere with workunits that could be executing. </p>
<h2><a class="anchor" id="integrate4"></a>
Step 4 - Clean Up Threads</h2>
<p>If you must execute something that could interfere (write to anything they could read or write) with work units, you should do that after <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a96d872719e50177ac5028c43bf68de21">FrameScheduler::JoinAllThreads()</a> is called. This joins, destroys, or otherwise cleans up the threads the scheduler has used depending on how this library is configured. </p>
<h2><a class="anchor" id="integrate5"></a>
Step 5 - Prepare for the next frame.</h2>
<p>All the work units are marked as complete and need to be reset with <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#af11e18b5ea39b77fee60c3a3d0e65bd4">FrameScheduler::ResetAllWorkUnits()</a> to be used by the next frame. This simply iterates over each work unit resetting their status. A potential future optimization could run this as a multithreaded monopoly instead. </p>
<h2><a class="anchor" id="integrate6"></a>
Step 6 - Wait for next frame.</h2>
<p>The final step is to wait until the next frame should begin. To do this tracking the begining of of each frame is required. The value in <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a2c2540f09e443e7d9f8bd2ed48354f93">FrameScheduler::CurrentFrameStart</a> is on <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html">FrameScheduler</a> construction to the current time, and reset every to the current time when <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#ac5babf56caf6f2a1bddfa461b9e999b2">FrameScheduler::WaitUntilNextFrame()</a> is called. The value set by <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#a36c450ded7b1df6276dafc699cdf1ee2">FrameScheduler::SetFrameRate()</a> is used to calculate the desired length of a frame in microseconds. If the begining of the next frame has not been reached, then this function will sleep the scheduler until the next frame should begin. To compensate for systems with an imprecise sleep mechanism (or timing mechanism) an internal <a class="el" href="classMezzanine_1_1Threading_1_1FrameScheduler.html#ae1494801b8b8c6f041d19abd9a332e46">FrameScheduler::TimingCostAllowance</a> is tracked that averages the effects of imprecision across multiple frames to prevent roundings errors from consistently lengthening of shortening frames. </p>
</div></div><!-- contents -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Sep 3 2013 23:25:06 for DagFrameScheduler by&#160;<a href="http://www.doxygen.org/index.html"><img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3.1</small></address>
</body>
</html>
